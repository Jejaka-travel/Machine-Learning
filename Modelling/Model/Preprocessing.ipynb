{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1886acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5617e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "rumah_sakit = pd.read_csv(\"C:/Users/LENOVO/Downloads/Rumah_Sakit.csv\")\n",
    "pemadam = pd.read_csv(\"C:/Users/LENOVO/Downloads/Pemadam.csv\")\n",
    "polisi = pd.read_csv(\"C:/Users/LENOVO/Downloads/Polisi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency = pd.concat([rumah_sakit, pemadam, polisi], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179bfbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7717d47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "types_dummies = pd.get_dummies(emergency['types'].str.get_dummies(','), prefix='types', prefix_sep='_')\n",
    "types_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([emergency, types_dummies], axis=1)\n",
    "df_all = df_all.drop(columns = [\"point_of_interest\", \"point_of_interest\", \"latlong\"])\n",
    "df_all = pd.merge(restaurant_review, df_all, on = \"place_id\")\n",
    "df_all.rename(columns={'rating': 'Ave_Rating'}, inplace=True)\n",
    "df_all['reviewers_Id'] = pd.factorize(df_all['reviewer_name'])[0] + 1\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19279715",
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency['types'] = emergency['types'].str.lower()\n",
    "emergency.loc[emergency['types'].str.contains('hospital'), 'types'] = 'hospital'\n",
    "emergency.loc[emergency['types'].str.contains('police'), 'types'] = 'police'\n",
    "emergency.loc[emergency['types'].str.contains('fire_station'), 'types'] = 'fire_station'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c11bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5632d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency = emergency[emergency['types'].isin(['police', 'fire_station', 'hospital'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bdffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca59cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency = emergency.drop(columns = [\"Unnamed: 0\", \"latlong\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_id = emergency.pop(\"place_id\")\n",
    "emergency.insert(0, 'place_id', place_id)\n",
    "emergency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8811edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency.rename(columns={'name': 'place_name'}, inplace=True)\n",
    "emergency.rename(columns={'formatted_address': 'place_address'}, inplace=True)\n",
    "emergency.rename(columns={'types': 'place_category'}, inplace=True)\n",
    "emergency.rename(columns={'user_ratings_total': 'total_review'}, inplace=True)\n",
    "emergency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a053331",
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency.rename(columns={'rating': 'ave_rating'}, inplace=True)\n",
    "emergency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92abb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency = emergency.drop_duplicates()\n",
    "emergency = emergency.reset_index()\n",
    "emergency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267f7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency = emergency.drop(columns = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647534c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7101eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "emergency.to_csv('D:/Project_Jejaka/emergency/emergency.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef1d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf79a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c44389",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emergency:\n",
    "    def __init__(self):\n",
    "        self.emergency = None\n",
    "        self.tfidf_matrix_emergency = None\n",
    "        self.similarity_tensor = None\n",
    "        self.load_data(\"D:/Project_Jejaka/emergency/emergency.csv\")\n",
    "        self.tfidf_matrix_emergency, self.tfidf = self.TF_IDF()\n",
    "        self.calculate_similarity(self.tfidf_matrix_emergency)\n",
    "        \n",
    "    def load_data(self, filename):\n",
    "        self.emergency = pd.read_csv(filename)\n",
    "        \n",
    "    def preprocess_text(self):\n",
    "        combined_text = self.emergency['place_name'] + ' ' + self.emergency['place_category'] + ' ' + self.emergency['place_address']\n",
    "        return combined_text\n",
    "    \n",
    "    def TF_IDF(self):\n",
    "        tfidf = TfidfVectorizer()\n",
    "        combined_text = self.preprocess_text()\n",
    "        tfidf_matrix = tfidf.fit_transform(combined_text)\n",
    "        return tfidf_matrix, tfidf\n",
    "    \n",
    "    def calculate_similarity(self, tfidf_matrix):\n",
    "        similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "        self.similarity_tensor = tf.convert_to_tensor(similarity_matrix)\n",
    "    \n",
    "    def recommend(self, input_text, k):\n",
    "        tfidf_matrix, tfidf = self.TF_IDF()\n",
    "        \n",
    "        tfidf_matrix_input = tfidf.transform([input_text])\n",
    "        similarity_scores = cosine_similarity(tfidf_matrix_input, tfidf_matrix)\n",
    "        similarity_scores = similarity_scores.flatten()\n",
    "        \n",
    "        top_k_values, top_k_indices = tf.nn.top_k(similarity_scores, k=k)\n",
    "        top_k_places = self.emergency.loc[top_k_indices]\n",
    "        \n",
    "        return top_k_places\n",
    "\n",
    "emer = Emergency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "emer = Emergency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0688368",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/recommend-emergency', methods=['POST'])\n",
    "def recommend_emergency():\n",
    "    data = request.json\n",
    "    input_text = data['input_text']\n",
    "    k = data['k']\n",
    "\n",
    "    emergency_places = emer.recommend(input_text, k)\n",
    "    recommended_places_json = emergency_places.to_dict(orient='records')\n",
    "\n",
    "    return jsonify({'places': recommended_places_json})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d34ef51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_data(filename):\n",
    "    return pd.read_csv(filename)\n",
    "\n",
    "def preprocess_text_hotel(data):\n",
    "    combined_text = data['place_name'] + ' ' + data['desc'] + ' ' + data['place_address']\n",
    "    return combined_text\n",
    "    variables = ['art_gallery', 'bakery', 'bar', 'cafe', 'clothing_store', 'electronics_store',\n",
    "                 'food', 'gym', 'health', 'home_goods_store', 'lodging', 'night_club',\n",
    "                 'park', 'parking', 'real_estate_agency', 'restaurant', 'shopping_mall',\n",
    "                 'spa', 'store', 'travel_agency']\n",
    "    \n",
    "    for variable in variables:\n",
    "        combined_text += data[data[variable] == 1][variable].apply(lambda x: ' ' + variable)\n",
    "    \n",
    "    return combined_text\n",
    "\n",
    "def preprocess_text_restaurant(data):\n",
    "    combined_text = data['place_name'] + ' ' + data['desc'] + ' ' + data['place_address']\n",
    "    return combined_text\n",
    "    variables = ['art_gallery', 'bakery', 'bar', 'cafe', 'food', 'liquor_store', 'lodging',\n",
    "                 'meal_delivery', 'meal_takeaway', 'night_club', 'restaurant', 'school', 'store']\n",
    "    \n",
    "    for variable in variables:\n",
    "        combined_text += data[data[variable] == 1][variable].apply(lambda x: ' ' + variable)\n",
    "    \n",
    "    return combined_text\n",
    "\n",
    "def preprocess_text_tourism(data):\n",
    "    combined_text = data['place_name'] + ' ' + data['desc'] + ' ' + data['place_address']\n",
    "    return combined_text\n",
    "    variables = ['amusement_park', 'aquarium', 'art_gallery', 'cafe', 'church', 'food',\n",
    "                 'hindu_temple', 'library', 'local_government_office', 'lodging', 'mosque',\n",
    "                 'museum', 'natural_feature', 'park', 'place_of_worship', 'restaurant',\n",
    "                 'rv_park', 'school', 'shopping_mall', 'store', 'travel_agency', 'zoo']\n",
    "    \n",
    "    for variable in variables:\n",
    "        combined_text += data[data[variable] == 1][variable].apply(lambda x: ' ' + variable)\n",
    "    \n",
    "    return combined_text\n",
    "\n",
    "def calculate_tfidf_matrix(combined_text):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform(combined_text)\n",
    "    return tfidf_matrix, tfidf\n",
    "\n",
    "tourism_place = load_data(\"D:/Project_Jejaka/tourism/item_data.csv\")\n",
    "tourism_combined_text = preprocess_text_tourism(tourism_place)\n",
    "tfidf_matrix_tourism, tfidf_tourism = calculate_tfidf_matrix(tourism_combined_text)\n",
    "\n",
    "restaurant_place = load_data(\"D:/Project_Jejaka/restaurant/item_data.csv\")\n",
    "restaurant_combined_text = preprocess_text_restaurant(restaurant_place)\n",
    "tfidf_matrix_restaurant, tfidf_restaurant = calculate_tfidf_matrix(restaurant_combined_text)\n",
    "\n",
    "hotel_place = load_data(\"D:/Project_Jejaka/hotel/item_data.csv\")\n",
    "hotel_combined_text = preprocess_text_hotel(hotel_place)\n",
    "tfidf_matrix_hotel, tfidf_hotel = calculate_tfidf_matrix(hotel_combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21fbddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tourism_combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cafb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_tourism, tfidf_tourism = calculate_tfidf_matrix(tourism_combined_text)\n",
    "tourism_similarity_tensor = calculate_similarity(tfidf_matrix_tourism)\n",
    "\n",
    "# Load restaurant data and perform necessary operations\n",
    "restaurant_place = load_data(\"D:/Project_Jejaka/restaurant/item_data.csv\")\n",
    "restaurant_combined_text = preprocess_text_restaurant(restaurant_place)\n",
    "tfidf_matrix_restaurant, tfidf_restaurant = calculate_tfidf_matrix(restaurant_combined_text)\n",
    "restaurant_similarity_tensor = calculate_similarity(tfidf_matrix_restaurant)\n",
    "\n",
    "# Load hotel data and perform necessary operations\n",
    "hotel_place = load_data(\"D:/Project_Jejaka/hotel/item_data.csv\")\n",
    "hotel_combined_text = preprocess_text_hotel(hotel_place)\n",
    "tfidf_matrix_hotel, tfidf_hotel = calculate_tfidf_matrix(hotel_combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7380d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix_hotel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37edddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(tfidf_restaurant, 'D:/Project_Jejaka/search-bar/tfidf_vectorizer_restaurant.joblib')\n",
    "joblib.dump(tfidf_hotel, 'D:/Project_Jejaka/search-bar/tfidf_vectorizer_hotel.joblib')\n",
    "joblib.dump(tfidf_tourism, 'D:/Project_Jejaka/search-bar/tfidf_vectorizer_tourism.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d319f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(tfidf_matrix_restaurant, 'D:/Project_Jejaka/search-bar/tfidf_matrix_restaurant.joblib')\n",
    "joblib.dump(tfidf_matrix_hotel, 'D:/Project_Jejaka/search-bar/tfidf_matrix_hotel.joblib')\n",
    "joblib.dump(tfidf_matrix_tourism, 'D:/Project_Jejaka/search-bar/tfidf_matrix_tourism.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f51bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = joblib.load('D:/Project_Jejaka/search-bar/tfidf_matrix_hotel.joblib')\n",
    "b = joblib.load('D:/Project_Jejaka/search-bar/tfidf_matrix_restaurant.joblib')\n",
    "c = joblib.load('D:/Project_Jejaka/search-bar/tfidf_matrix_tourism.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4317859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text = tourism_combined_text + restaurant_combined_text + hotel_combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2afb52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0579ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa78b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tourism_place['place_name'] + ' ' + tourism_place['desc'] + ' ' + tourism_place['place_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa0aafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6879f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = pd.read_csv(\"D:/Project_Jejaka/hotel/item_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5312bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baca463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memproses alamat\n",
    "def process_address(address):\n",
    "    city_mapping = {\n",
    "        'yogyakarta': 'Yogyakarta',\n",
    "        'bandung': 'Bandung',\n",
    "        'malang': 'Malang',\n",
    "        'padang': 'Padang',\n",
    "        'medan': 'Medan',\n",
    "        'bali': 'Bali',\n",
    "        'jakarta': 'Jakarta',\n",
    "        'lombok': 'Lombok',\n",
    "        'surakarta': 'Surakarta',\n",
    "        'batam': 'Batam',\n",
    "    }\n",
    "    \n",
    "    address_lower = address.lower()\n",
    "    \n",
    "    for city, city_name in city_mapping.items():\n",
    "        if city in address_lower:\n",
    "            return city_name\n",
    "    \n",
    "    return ''\n",
    "\n",
    "# Menambahkan kolom baru \"city\" berdasarkan alamat\n",
    "item_data.insert(item_data.columns.get_loc('place_address') + 1, 'city/regency', item_data['place_address'].apply(process_address))\n",
    "\n",
    "# Menampilkan DataFrame hasil\n",
    "item_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc036fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data[\"city/regency\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2216d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data.to_csv('item_data_hotel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b144755",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data = pd.read_csv(\"C:/Users/LENOVO/item_data_restaurant.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c0e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa1713",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_data.to_csv('item_data_restaurant.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f56a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from google.cloud import bigquery\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Mengatur kredensial BigQuery\n",
    "credentials_path = \"direct-hope-387806-8d2b15781824.json\"  # Ganti dengan path file JSON kunci yang Anda unduh\n",
    "\n",
    "# Membuat objek koneksi BigQuery\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_path\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Load item data\n",
    "item_data_tourism = None\n",
    "item_data_restaurant = None\n",
    "item_data_hotel = None\n",
    "\n",
    "def load_data():\n",
    "    global item_data_tourism, item_data_restaurant, item_data_hotel\n",
    "    \n",
    "    # Load item data from BigQuery\n",
    "    item_data_tourism = load_data_from_bigquery('item_data_tourism', ['place_id', 'place_name', 'desc', 'place_address', 'total_review', 'ave_rating'])\n",
    "    item_data_restaurant = load_data_from_bigquery('item_data_restaurant', ['place_id', 'place_name', 'desc', 'place_address', 'total_review', 'ave_rating'])\n",
    "    item_data_hotel = load_data_from_bigquery('item_data_hotel', ['place_id', 'place_name', 'desc', 'place_address', 'total_review', 'ave_rating'])\n",
    "    \n",
    "    item_data_tourism['city'] = item_data_tourism['place_address'].apply(lambda x: x.split()[-1])\n",
    "    item_data_restaurant['city'] = item_data_restaurant['place_address'].apply(lambda x: x.split()[-1])\n",
    "    item_data_hotel['city'] = item_data_hotel['place_address'].apply(lambda x: x.split()[-1])\n",
    "\n",
    "def load_data_from_bigquery(table_name, selected_columns=None):\n",
    "    table_ref = client.dataset('Jejaka').table(table_name)\n",
    "    table = client.get_table(table_ref)\n",
    "    \n",
    "    if selected_columns is None:\n",
    "        data = client.list_rows(table).to_dataframe()\n",
    "    else:\n",
    "        schema = table.schema\n",
    "        selected_fields = [field for field in schema if field.name in selected_columns]\n",
    "        data = client.list_rows(table, selected_fields=selected_fields).to_dataframe()\n",
    "    \n",
    "    return data\n",
    "\n",
    "@app.route('/search', methods=['POST'])\n",
    "def search():\n",
    "    # Get input text and filters from the request\n",
    "    data = request.get_json()\n",
    "    input_text = data.get('input_text', '')\n",
    "    filters = data.get('filters', [])  # Use a list of filters\n",
    "\n",
    "    # Combine the item data based on the selected filters\n",
    "    if 'tourism' in filters:\n",
    "        item_data = item_data_tourism\n",
    "    if 'restaurant' in filters:\n",
    "        item_data = item_data_restaurant\n",
    "    if 'hotel' in filters:\n",
    "        item_data = item_data_hotel\n",
    "\n",
    "    # Create a TF-IDF vectorizer and fit it on the item data\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(item_data['place_name'] + ' ' + item_data['desc'] + ' ' + item_data['place_address'])\n",
    "\n",
    "    # Transform input text using TF-IDF vectorizer\n",
    "    tfidf_matrix_input = tfidf_vectorizer.transform([input_text])\n",
    "\n",
    "    # Perform cosine similarity and get top-k results\n",
    "    similarity_scores = cosine_similarity(tfidf_matrix_input, tfidf_matrix)\n",
    "    similarity_scores = similarity_scores.flatten()\n",
    "    top_k_indices = np.argsort(similarity_scores)[::-1][:20]\n",
    "    top_k_places = item_data.iloc[top_k_indices]\n",
    "\n",
    "    # Convert the results to a JSON response\n",
    "    results = []\n",
    "    for index, row in top_k_places.iterrows():\n",
    "        result = {\n",
    "            'place_id': row['place_id'],\n",
    "            'place_name': row['place_name'],\n",
    "            'place_address': row['place_address'],\n",
    "            'total_review': row['total_review'],\n",
    "            'ave_rating': row['ave_rating']\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    return jsonify({'results': results})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    load_data()\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76140c89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
